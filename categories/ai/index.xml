<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ai on devbins blog</title>
    <link>http://devbins.github.io/categories/ai/</link>
    <description>Recent content in Ai on devbins blog</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Mon, 21 Jul 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://devbins.github.io/categories/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Cloudflare AI Gateway</title>
      <link>http://devbins.github.io/post/cloudflare_aigateway/</link>
      <pubDate>Mon, 21 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://devbins.github.io/post/cloudflare_aigateway/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;最近 Google 的 Gemini 的模型又有免费额度，但是在国内无法使用。&lt;/p&gt;</description>
    </item>
    <item>
      <title>AnyRouter 白嫖 Claude Code</title>
      <link>http://devbins.github.io/post/anyrouter/</link>
      <pubDate>Tue, 08 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://devbins.github.io/post/anyrouter/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;Claude的模型在编程方面非常强，奈何非常贵，并且还要有一个好的网络才能用。&lt;/p&gt;&#xA;&lt;p&gt;不过最近有anyrouter可以白嫖，也不需要魔法就能使用，非常方便。&lt;/p&gt;&#xA;&lt;p&gt;不管如何先把账号注册了，万一后面没白嫖机会了。&lt;/p&gt;&#xA;&lt;p&gt;记得上次 DeepSeek 就后悔没有早点白嫖，白白错过了。&lt;/p&gt;</description>
    </item>
    <item>
      <title>在Ollama 上运行 DeepSeek 大模型</title>
      <link>http://devbins.github.io/post/ollama_deepseek/</link>
      <pubDate>Tue, 21 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://devbins.github.io/post/ollama_deepseek/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;今天在群里有个小伙伴发了一个在 &lt;code&gt;Ollama&lt;/code&gt; 上运行 &lt;code&gt;deepseek&lt;/code&gt; 大模型的消息，最近 &lt;code&gt;deepkseek&lt;/code&gt; 也是风头正劲，于是我就体验了一下。&lt;/p&gt;&#xA;&lt;p&gt;发现了还不错，它相比于其它的大模型会把思考过程也显示出来。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mac 部署LLaMA2</title>
      <link>http://devbins.github.io/post/llama/</link>
      <pubDate>Sun, 20 Aug 2023 00:00:00 +0000</pubDate>
      <guid>http://devbins.github.io/post/llama/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;前不久 &lt;code&gt;Meta&lt;/code&gt; 开源了&lt;a href=&#34;https://ai.meta.com/llama/&#34;&gt;Llama 2 - Meta AI&lt;/a&gt; ，并且是可商用的。&lt;/p&gt;&#xA;&lt;p&gt;所以今天要在 &lt;code&gt;Mac&lt;/code&gt; 上搭建 &lt;code&gt;Llama&lt;/code&gt; ，由于 &lt;code&gt;Llama&lt;/code&gt; 需要非常高的内存普通玩家玩不起，所以为了在 &lt;code&gt;Mac&lt;/code&gt; 上跑起来就有了&lt;a href=&#34;https://github.com/ggerganov/llama.cpp/tree/master&#34;&gt;ggerganov/llama.cpp: Port of Facebook&amp;rsquo;s LLaMA model in C/C++&lt;/a&gt; ，本文也是采用 &lt;code&gt;llama.cpp&lt;/code&gt; 的方式进行部署。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mac 体验ChatGLM2-6B</title>
      <link>http://devbins.github.io/post/chatglm/</link>
      <pubDate>Mon, 14 Aug 2023 00:00:00 +0000</pubDate>
      <guid>http://devbins.github.io/post/chatglm/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;前不久换了新 &lt;code&gt;Mac&lt;/code&gt; ，性能还可以，于是就想试着体验一下 &lt;code&gt;ChatGLM&lt;/code&gt; ，看看能不能跑起来。&lt;/p&gt;&#xA;&lt;p&gt;所以今天就来体验一下 &lt;code&gt;ChatGLM2-6B&lt;/code&gt; 。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
