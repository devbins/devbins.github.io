<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI on devbins blog</title>
    <link>http://devbins.github.io/categories/ai/</link>
    <description>Recent content in AI on devbins blog</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Wed, 03 Sep 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://devbins.github.io/categories/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>qwen-code配合魔搭每天2000次调用</title>
      <link>http://devbins.github.io/post/qwen-code/</link>
      <pubDate>Wed, 03 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://devbins.github.io/post/qwen-code/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;阿里百炼的 100 万 token 用完了，虽然模型挺多的，但是并不是每个都能在 &lt;code&gt;Claude Code&lt;/code&gt; 中使用。&lt;/p&gt;&#xA;&lt;p&gt;于是转向魔搭社区，它每天有 2000 次免费调用，足够使用了，顺便体验一下 &lt;code&gt;Qwen-code&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;毕竟都用 AI 写代码了，乐趣就没了。&lt;/p&gt;</description>
    </item>
    <item>
      <title>百万 token 用完了，换其它的</title>
      <link>http://devbins.github.io/post/claude_code_router/</link>
      <pubDate>Tue, 02 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://devbins.github.io/post/claude_code_router/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;在之前的文章中，使用阿里百炼接入了 &lt;code&gt;Claude Code&lt;/code&gt; ，并且提供了 100 万的免费 token。&lt;/p&gt;&#xA;&lt;p&gt;奈何不经用，一个小需求就把 &lt;code&gt;token&lt;/code&gt; 用完了。&lt;/p&gt;&#xA;&lt;p&gt;100 万看起来很多，实际也就 &lt;code&gt;1000000 / 1024 / 1024 = 0.9536743164&lt;/code&gt; 约等于呀 1M，还不到。&lt;/p&gt;</description>
    </item>
    <item>
      <title>阿里百炼接入 Claude Code</title>
      <link>http://devbins.github.io/post/claude_code_bailian/</link>
      <pubDate>Sun, 31 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://devbins.github.io/post/claude_code_bailian/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;Claude Code 用起来是真心疼，问了两个问题就花了约 $1, 实在是钱包不允许这么挥霍。&lt;/p&gt;&#xA;&lt;p&gt;于是想要使用其它模型来接入 Claude Code，尝试了一下阿里的百炼，发现异常的简单。&lt;/p&gt;&#xA;&lt;p&gt;关键是新人还有 100 万免费 token，香。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cloudflare AI Gateway</title>
      <link>http://devbins.github.io/post/cloudflare_aigateway/</link>
      <pubDate>Mon, 21 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://devbins.github.io/post/cloudflare_aigateway/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;最近 Google 的 Gemini 的模型又有免费额度，但是在国内无法使用。&lt;/p&gt;</description>
    </item>
    <item>
      <title>AnyRouter 白嫖 Claude Code</title>
      <link>http://devbins.github.io/post/anyrouter/</link>
      <pubDate>Tue, 08 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://devbins.github.io/post/anyrouter/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;Claude的模型在编程方面非常强，奈何非常贵，并且还要有一个好的网络才能用。&lt;/p&gt;&#xA;&lt;p&gt;不过最近有anyrouter可以白嫖，也不需要魔法就能使用，非常方便。&lt;/p&gt;&#xA;&lt;p&gt;不管如何先把账号注册了，万一后面没白嫖机会了。&lt;/p&gt;&#xA;&lt;p&gt;记得上次 DeepSeek 就后悔没有早点白嫖，白白错过了。&lt;/p&gt;</description>
    </item>
    <item>
      <title>在Ollama 上运行 DeepSeek 大模型</title>
      <link>http://devbins.github.io/post/ollama_deepseek/</link>
      <pubDate>Tue, 21 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://devbins.github.io/post/ollama_deepseek/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;今天在群里有个小伙伴发了一个在 &lt;code&gt;Ollama&lt;/code&gt; 上运行 &lt;code&gt;deepseek&lt;/code&gt; 大模型的消息，最近 &lt;code&gt;deepkseek&lt;/code&gt; 也是风头正劲，于是我就体验了一下。&lt;/p&gt;&#xA;&lt;p&gt;发现了还不错，它相比于其它的大模型会把思考过程也显示出来。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mac 部署LLaMA2</title>
      <link>http://devbins.github.io/post/llama/</link>
      <pubDate>Sun, 20 Aug 2023 00:00:00 +0000</pubDate>
      <guid>http://devbins.github.io/post/llama/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;前不久 &lt;code&gt;Meta&lt;/code&gt; 开源了&lt;a href=&#34;https://ai.meta.com/llama/&#34;&gt;Llama 2 - Meta AI&lt;/a&gt; ，并且是可商用的。&lt;/p&gt;&#xA;&lt;p&gt;所以今天要在 &lt;code&gt;Mac&lt;/code&gt; 上搭建 &lt;code&gt;Llama&lt;/code&gt; ，由于 &lt;code&gt;Llama&lt;/code&gt; 需要非常高的内存普通玩家玩不起，所以为了在 &lt;code&gt;Mac&lt;/code&gt; 上跑起来就有了&lt;a href=&#34;https://github.com/ggerganov/llama.cpp/tree/master&#34;&gt;ggerganov/llama.cpp: Port of Facebook&amp;rsquo;s LLaMA model in C/C++&lt;/a&gt; ，本文也是采用 &lt;code&gt;llama.cpp&lt;/code&gt; 的方式进行部署。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mac 体验ChatGLM2-6B</title>
      <link>http://devbins.github.io/post/chatglm/</link>
      <pubDate>Mon, 14 Aug 2023 00:00:00 +0000</pubDate>
      <guid>http://devbins.github.io/post/chatglm/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;前不久换了新 &lt;code&gt;Mac&lt;/code&gt; ，性能还可以，于是就想试着体验一下 &lt;code&gt;ChatGLM&lt;/code&gt; ，看看能不能跑起来。&lt;/p&gt;&#xA;&lt;p&gt;所以今天就来体验一下 &lt;code&gt;ChatGLM2-6B&lt;/code&gt; 。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
