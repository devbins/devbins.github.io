<!DOCTYPE html>
<html lang="zh-cn">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Mac 体验ChatGLM2-6B - devbins blog</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="前言 前不久换了新 Mac ，性能还可以，于是就想试着体验一下 ChatGLM ，看看能不能跑起来。
所以今天就来体验一下 ChatGLM2-6B 。
" /><meta name="keywords" content="devbins, Emacs, ArchLinux" />






<meta name="generator" content="Hugo 0.147.8 with theme even" />


<link rel="canonical" href="http://localhost:1313/post/chatglm/" />
<link rel="apple-touch-icon" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="manifest" href="../../manifest.json">
<link rel="mask-icon" href="../../safari-pinned-tab.svg" color="#5bbad5">



<link href="../../sass/main.min.7a55213d2525d355f504faa45fc0a8facd4792244eed4e42ebc5f1a55a83d427.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="http://localhost:1313/post/chatglm/">
  <meta property="og:site_name" content="devbins blog">
  <meta property="og:title" content="Mac 体验ChatGLM2-6B">
  <meta property="og:description" content="前言 前不久换了新 Mac ，性能还可以，于是就想试着体验一下 ChatGLM ，看看能不能跑起来。
所以今天就来体验一下 ChatGLM2-6B 。">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2023-08-14T00:00:00+00:00">
    <meta property="article:modified_time" content="2023-08-14T00:00:00+00:00">
    <meta property="article:tag" content="Ai">

  <meta itemprop="name" content="Mac 体验ChatGLM2-6B">
  <meta itemprop="description" content="前言 前不久换了新 Mac ，性能还可以，于是就想试着体验一下 ChatGLM ，看看能不能跑起来。
所以今天就来体验一下 ChatGLM2-6B 。">
  <meta itemprop="datePublished" content="2023-08-14T00:00:00+00:00">
  <meta itemprop="dateModified" content="2023-08-14T00:00:00+00:00">
  <meta itemprop="wordCount" content="1233">
  <meta itemprop="keywords" content="Ai">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Mac 体验ChatGLM2-6B">
  <meta name="twitter:description" content="前言 前不久换了新 Mac ，性能还可以，于是就想试着体验一下 ChatGLM ，看看能不能跑起来。
所以今天就来体验一下 ChatGLM2-6B 。">
 <meta property="og:url" content="http://localhost:1313/post/chatglm/">
  <meta property="og:site_name" content="devbins blog">
  <meta property="og:title" content="Mac 体验ChatGLM2-6B">
  <meta property="og:description" content="前言 前不久换了新 Mac ，性能还可以，于是就想试着体验一下 ChatGLM ，看看能不能跑起来。
所以今天就来体验一下 ChatGLM2-6B 。">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2023-08-14T00:00:00+00:00">
    <meta property="article:modified_time" content="2023-08-14T00:00:00+00:00">
    <meta property="article:tag" content="Ai">

  <meta itemprop="name" content="Mac 体验ChatGLM2-6B">
  <meta itemprop="description" content="前言 前不久换了新 Mac ，性能还可以，于是就想试着体验一下 ChatGLM ，看看能不能跑起来。
所以今天就来体验一下 ChatGLM2-6B 。">
  <meta itemprop="datePublished" content="2023-08-14T00:00:00+00:00">
  <meta itemprop="dateModified" content="2023-08-14T00:00:00+00:00">
  <meta itemprop="wordCount" content="1233">
  <meta itemprop="keywords" content="Ai">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Mac 体验ChatGLM2-6B">
  <meta name="twitter:description" content="前言 前不久换了新 Mac ，性能还可以，于是就想试着体验一下 ChatGLM ，看看能不能跑起来。
所以今天就来体验一下 ChatGLM2-6B 。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="../../" class="logo">devbins</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="../../">
        <li class="mobile-menu-item">Home</li>
      </a><a href="../../post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="../../tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="../../categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="../../about/">
        <li class="mobile-menu-item">About</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="../../" class="logo">devbins</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="../../">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="../../post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="../../tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="../../categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="../../about/">About</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Mac 体验ChatGLM2-6B</h1>

      <div class="post-meta">
        <span class="post-time"> 2023-08-14 </span>
        <div class="post-category">
            <a href="../../categories/ai/"> Ai </a>
            </div>
          <span class="more-meta"> 约 1233 字 </span>
          <span class="more-meta"> 预计阅读 3 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#前言">前言</a></li>
    <li><a href="#安装">安装</a></li>
    <li><a href="#快速在命令行中体验">快速在命令行中体验</a></li>
    <li><a href="#web-版本">web 版本</a></li>
    <li><a href="#web-版本-2">web 版本 2</a></li>
    <li><a href="#api-部署">api 部署</a></li>
    <li><a href="#总结">总结</a></li>
    <li><a href="#参考">参考</a></li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <h2 id="前言">前言</h2>
<p>前不久换了新 <code>Mac</code> ，性能还可以，于是就想试着体验一下 <code>ChatGLM</code> ，看看能不能跑起来。</p>
<p>所以今天就来体验一下 <code>ChatGLM2-6B</code> 。</p>
<h2 id="安装">安装</h2>
<p>我这里使用 <code>Anaconda</code> 创建一个 <code>Python 3.9</code> 的环境进行 <code>ChatGLM2-6B</code> 的环境搭建。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">conda create -n chatglm2 <span class="nv">python</span><span class="o">=</span>3.9
</span></span><span class="line"><span class="cl">conda activate chatglm2
</span></span><span class="line"><span class="cl">git clone https://github.com/THUDM/ChatGLM2-6B.git
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> ChatGLM2-6B
</span></span><span class="line"><span class="cl">pip3 install -r requirements.txt
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="快速在命令行中体验">快速在命令行中体验</h2>
<p>安装好之后，打开终端，输入 <code>python</code> 然后把下面的代码敲一遍</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">from transformers import AutoTokenizer, AutoModel
</span></span><span class="line"><span class="cl"><span class="nv">tokenizer</span> <span class="o">=</span> AutoTokenizer.from_pretrained<span class="o">(</span><span class="s2">&#34;THUDM/chatglm2-6b&#34;</span>, <span class="nv">trust_remote_code</span><span class="o">=</span>True<span class="o">)</span>
</span></span><span class="line"><span class="cl"><span class="nv">model</span> <span class="o">=</span> AutoModel.from_pretrained<span class="o">(</span><span class="s2">&#34;THUDM/chatglm2-6b&#34;</span>, <span class="nv">trust_remote_code</span><span class="o">=</span>True<span class="o">)</span>.to<span class="o">(</span><span class="s1">&#39;mps&#39;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl"><span class="nv">model</span> <span class="o">=</span> model.eval<span class="o">()</span>
</span></span><span class="line"><span class="cl">response, <span class="nb">history</span> <span class="o">=</span> model.chat<span class="o">(</span>tokenizer, <span class="s2">&#34;你好&#34;</span>, <span class="nv">history</span><span class="o">=[])</span>
</span></span><span class="line"><span class="cl">print<span class="o">(</span>response<span class="o">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>这个过程中会从<a href="https://huggingface.co/THUDM/chatglm2-6b/tree/main">THUDM/chatglm2-6b at main</a> 下载模型，时间会比较久，下载完成之后能看到输出如下响应，说明搭建成功了。如果失败了，可以重新运行，主要还是要解决网络的问题。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-text" data-lang="text"><span class="line"><span class="cl">你好👋!我是人工智能助手 ChatGLM2-6B,很高兴见到你,欢迎问我任何问题。
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="web-版本">web 版本</h2>
<p>在命令行中体验一下还可以，真的使用起来其实是非常麻烦的，还要手输代码。</p>
<p>所以在 <code>ChatGLM2-6B</code> 中还提供了网页版的，使用起来就非常方便了。</p>
<p>在 <code>ChatGLM2-6B</code> 中有 <code>web_demo.py</code> 和 <code>web_demo2.py</code> 这两个文件，我们都去体验一下，不过在体验之前我们需要改动一下代码，因为我们是在 <code>Apple Silicon</code> 上运行的，而代码默认写的是英伟达的 <code>cuda</code> 。</p>
<p>找到 <code>web_demo.py</code> 中的</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&#34;THUDM/chatglm2-6b&#34;</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>将其改为</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="nv">model</span> <span class="o">=</span> AutoModel.from_pretrained<span class="o">(</span><span class="s2">&#34;THUDM/chatglm2-6b&#34;</span>, <span class="nv">trust_remote_code</span><span class="o">=</span>True<span class="o">)</span>.to<span class="o">(</span><span class="s1">&#39;mps&#39;</span><span class="o">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>改好之后执行以下命令就能够跑起来了，运行会花点时间。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">python web_demo.py
</span></span></code></pre></td></tr></table>
</div>
</div><p>启动之后会自动帮你打开浏览器并跳转到 <a href="http://127.0.0.1:7860/">http://127.0.0.1:7860/</a>
<img src="../../images/chatglm/chatglm_gradio.png" alt="">
这个界面就非常友好和简单，它是基于 <code>Gradio</code> 的。下面的输入框就是我们输入问题的地方，上面的就是 <code>ChatGLM2-6B</code> 和我们问答。</p>
<h2 id="web-版本-2">web 版本 2</h2>
<p>除了基于 <code>Gradio</code> 的版本，还有一个基于 <code>Streamlit</code> 的版本，官方说这个版本更流畅。</p>
<p>在使用 <code>Streamlit</code> 之前需要先安装一下</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">pip install streamlit
</span></span></code></pre></td></tr></table>
</div>
</div><p>安装好之后，还是需要改一下代码，把 <code>cuda</code> 改成 <code>mps</code> 。</p>
<p>找到 <code>web_demo2.py</code> 同样的</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&#34;THUDM/chatglm2-6b&#34;</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>将其改为</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="nv">model</span> <span class="o">=</span> AutoModel.from_pretrained<span class="o">(</span><span class="s2">&#34;THUDM/chatglm2-6b&#34;</span>, <span class="nv">trust_remote_code</span><span class="o">=</span>True<span class="o">)</span>.to<span class="o">(</span><span class="s1">&#39;mps&#39;</span><span class="o">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>改好之后就可以使用 <code>streamlit run web_demo2.py</code> 来运行程序了。</p>
<p>同样运行起来之后会自动帮你打开浏览器并跳转到 <a href="http://localhost:8501/">http://localhost:8501/</a>
<img src="../../images/chatglm/chatglm_streamlit.png" alt=""></p>
<p><code>streamlit</code> 打开的过程中会有界面，不像 <code>Gradio</code> 只有在准备好之后才会打开，所以在没有准备好之前 <code>Gradio</code> 是看不到界面的，会卡一会。</p>
<p>不过 <code>streamlit</code> 有个 bug，在点击发送之后，输入框的内容还在，并没有清空输入框。</p>
<p><code>Streamlit</code> 和 <code>Gradio</code> 两个版本都有一个同样的问题，是输入回车只会换行，不会发送问题给 <code>ChatGLM</code> 。</p>
<h2 id="api-部署">api 部署</h2>
<p>作为一个程序员最喜欢的就是有 API 可以用，幸运的是 <code>ChatGLM2-6B</code> 提供了 <code>API</code> 部署的方式。</p>
<p>在部署之前需要先安装 <code>fastapi uvicorn</code> ，可以用如下指令进行安装</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">pip install fastapi uvicorn
</span></span></code></pre></td></tr></table>
</div>
</div><p>老规矩，还是要把 <code>cuda</code> 改成 <code>mps</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&#34;THUDM/chatglm2-6b&#34;</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>将其改为</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="nv">model</span> <span class="o">=</span> AutoModel.from_pretrained<span class="o">(</span><span class="s2">&#34;THUDM/chatglm2-6b&#34;</span>, <span class="nv">trust_remote_code</span><span class="o">=</span>True<span class="o">)</span>.to<span class="o">(</span><span class="s1">&#39;mps&#39;</span><span class="o">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>改好之后就可以运行了</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">python api.py
</span></span></code></pre></td></tr></table>
</div>
</div><p>接着我们就可以使用 <code>POST</code> 进行调用了</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">curl -X POST <span class="s2">&#34;http://127.0.0.1:8000&#34;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>     -H <span class="s1">&#39;Content-Type: application/json&#39;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>     -d <span class="s1">&#39;{&#34;prompt&#34;: &#34;你好&#34;, &#34;history&#34;: []}&#39;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>得到结果如下</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-json" data-lang="json"><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&#34;response&#34;</span><span class="p">:</span> <span class="s2">&#34;你好👋！我是人工智能助手 ChatGLM2-6B，很高兴见到你，欢迎问我任何问题。&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&#34;history&#34;</span><span class="p">:</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="p">[</span>
</span></span><span class="line"><span class="cl">      <span class="s2">&#34;你好&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="s2">&#34;你好👋！我是人工智能助手 ChatGLM2-6B，很高兴见到你，欢迎问我任何问题。&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="p">],</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&#34;status&#34;</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&#34;time&#34;</span><span class="p">:</span> <span class="s2">&#34;2023-08-14 23:13:13&#34;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>有了 <code>API</code> 就能根据自己想象力，自己拓展开发一些应用出来。</p>
<h2 id="总结">总结</h2>
<ol>
<li>搭建 <code>ChatGLM2-6B</code> 还是挺简单的，本地回答的速度挺快，几乎能做到秒回。</li>
<li><code>ChatGLM2-6B</code> 提供了 web 的方式来回答问题，挺好用，但是有一些小问题需要改进。</li>
<li><code>ChatGLM2-6B</code> 提供 <code>API</code> 的方式，让我们自己开发基于 <code>ChatGLM2-6B</code> 也变得非常方便。</li>
</ol>
<h2 id="参考">参考</h2>
<ul>
<li><a href="https://github.com/THUDM/ChatGLM2-6B">THUDM/ChatGLM2-6B: ChatGLM2-6B: An Open Bilingual Chat LLM | 开源双语对话语言模型</a></li>
</ul>
    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2023-08-14
        
    </span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">许可协议</span>
    <span class="item-content"><a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">CC BY-NC-ND 4.0</a></span>
  </p>
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="../../tags/ai/">Ai</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="../../post/llama/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Mac 部署LLaMA2</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="../../post/lambda%E6%8D%95%E8%8E%B7/">
            <span class="next-text nav-default">C&#43;&#43; Lambda捕获局部变量与成员变量</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        <div id="gitalk-container"></div>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js" crossorigin="anonymous"></script>
    <script type="text/javascript">
      var gitalk = new Gitalk({
        id: '2023-08-14 00:00:00 \u002b0000 UTC',
        title: 'Mac 体验ChatGLM2-6B',
        clientID: '1234e4dd9e0ad49470be',
        clientSecret: '9acb7351fca3dcca6d3cc50be8a1d2cf329f4163',
        repo: 'devbins.github.io',
        owner: 'devbins',
        admin: ['devbins'],
        body: decodeURI(location.href)
      });
      gitalk.render('gitalk-container');
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://github.com/gitalk/gitalk">comments powered by gitalk.</a></noscript>

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="binshengh@gmail.com" class="iconfont icon-email" title="email"></a>
      <a href="https://github.com/devbins" class="iconfont icon-github" title="github"></a>
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io"
      >Hugo</a
    > 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 -
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even"
      >Even</a
    >
  </span>

  

  <span class="copyright-year">
    &copy;
    2016 -
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="../../js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>








</body>
</html>
